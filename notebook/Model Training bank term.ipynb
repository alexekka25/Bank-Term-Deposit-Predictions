{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e754518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e08b7ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"D:\\Projects\\archive\\train.csv\")\n",
    "test_df = pd.read_csv(r\"D:\\Projects\\archive\\test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b3e073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0006a6b2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_train = train_df.isnull().sum()\n",
    "print(\"Missing values in training data:\")\n",
    "print(missing_train)\n",
    "\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_cols = train_df.select_dtypes(include=['object']).columns\n",
    "train_df_encoded = pd.get_dummies(train_df, columns=categorical_cols, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8684b870",
   "metadata": {},
   "source": [
    "#  Scale numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c7f793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_cols = train_df_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "train_df_encoded[numerical_cols] = scaler.fit_transform(train_df_encoded[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b4c0f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in testing data:\n",
      "age          0\n",
      "job          0\n",
      "marital      0\n",
      "education    0\n",
      "default      0\n",
      "balance      0\n",
      "housing      0\n",
      "loan         0\n",
      "contact      0\n",
      "day          0\n",
      "month        0\n",
      "duration     0\n",
      "campaign     0\n",
      "pdays        0\n",
      "previous     0\n",
      "poutcome     0\n",
      "y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_test = test_df.isnull().sum()\n",
    "print(\"Missing values in testing data:\")\n",
    "print(missing_test)\n",
    "\n",
    "\n",
    "# Encode categorical variables (ensure same columns as training data)\n",
    "test_df_encoded = pd.get_dummies(test_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Align test data columns with training data\n",
    "test_df_encoded = test_df_encoded.reindex(columns=train_df_encoded.columns, fill_value=0)\n",
    "\n",
    "# Scale numerical features (using the same scaler as training data)\n",
    "test_df_encoded[numerical_cols] = scaler.transform(test_df_encoded[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b6a63",
   "metadata": {},
   "source": [
    "# 3. Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92522187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training data\n",
    "X_train = train_df_encoded.drop('y_yes', axis=1)  \n",
    "y_train = train_df_encoded['y_yes']\n",
    "\n",
    "# For testing data\n",
    "X_test = test_df_encoded.drop('y_yes', axis=1)\n",
    "y_test = test_df_encoded['y_yes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8143d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.98      0.95      4000\n",
      "        True       0.65      0.33      0.44       521\n",
      "\n",
      "    accuracy                           0.90      4521\n",
      "   macro avg       0.78      0.65      0.69      4521\n",
      "weighted avg       0.89      0.90      0.89      4521\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3905   95]\n",
      " [ 348  173]]\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00      4000\n",
      "        True       1.00      1.00      1.00       521\n",
      "\n",
      "    accuracy                           1.00      4521\n",
      "   macro avg       1.00      1.00      1.00      4521\n",
      "weighted avg       1.00      1.00      1.00      4521\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4000    0]\n",
      " [   0  521]]\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.98      0.95      4000\n",
      "        True       0.77      0.40      0.53       521\n",
      "\n",
      "    accuracy                           0.92      4521\n",
      "   macro avg       0.85      0.69      0.74      4521\n",
      "weighted avg       0.91      0.92      0.91      4521\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3938   62]\n",
      " [ 313  208]]\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.99      0.97      4000\n",
      "        True       0.87      0.69      0.77       521\n",
      "\n",
      "    accuracy                           0.95      4521\n",
      "   macro avg       0.92      0.84      0.87      4521\n",
      "weighted avg       0.95      0.95      0.95      4521\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3946   54]\n",
      " [ 161  360]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_log_reg))\n",
    "\n",
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "# Gradient Boosting (e.g., XGBoost)\n",
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42106d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Training Accuracy: 1.00\n",
      "Random Forest Test Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "train_accuracy_rf = rf_clf.score(X_train, y_train)\n",
    "print(f\"Random Forest Training Accuracy: {train_accuracy_rf:.2f}\")\n",
    "\n",
    "# Test accuracy\n",
    "test_accuracy_rf = rf_clf.score(X_test, y_test)\n",
    "print(f\"Random Forest Test Accuracy: {test_accuracy_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908be7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
